{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2, os, shutil, math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Lambda, Flatten, Reshape, Conv2D, MaxPooling2D, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Add, Reshape, AveragePooling2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, array_to_img, img_to_array\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(df, n, working_dir, img_size):\n",
    "    df = df.copy()\n",
    "    print('Initial length of dataframe is ', len(df))\n",
    "    aug_dir = os.path.join(working_dir, 'aug')\n",
    "    if os.path.isdir(aug_dir):\n",
    "        shutil.rmtree(aug_dir)\n",
    "    os.mkdir(aug_dir)\n",
    "\n",
    "    for label in df['labels'].unique():\n",
    "        dir_path = os.path.join(aug_dir, label)\n",
    "        os.mkdir(dir_path)\n",
    "    total = 0\n",
    "    gen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        shear_range=0.2,  # Thêm shear\n",
    "        fill_mode='reflect',  # Thay đổi từ 'nearest' sang 'reflect'\n",
    "        brightness_range=[0.8, 1.2],  # Thêm brightness augmentation\n",
    "        channel_shift_range=50.0,  # Thêm channel shift\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    groups = df.groupby('labels')\n",
    "    for label in df['labels'].unique():\n",
    "        group = groups.get_group(label)\n",
    "        sample_count = len(group)\n",
    "        if sample_count < n:\n",
    "            aug_img_count = 0\n",
    "            delta = n - sample_count\n",
    "            target_dir = os.path.join(aug_dir, label)\n",
    "            msg = '{0:40s} for class {1:^30s} creating {2:^5s} augmented images'.format(' ', label, str(delta))\n",
    "            print(msg, '\\r', end='')  # prints over on the same line\n",
    "            aug_gen = gen.flow_from_dataframe(group, x_col='filepaths', y_col=None, target_size=img_size,\n",
    "                                              class_mode=None, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                                              save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',\n",
    "                                              save_format='jpg')\n",
    "            while aug_img_count < delta:\n",
    "                images = next(aug_gen)\n",
    "                aug_img_count += len(images)\n",
    "            total += aug_img_count\n",
    "    print('Total Augmented images created= ', total)\n",
    "    aug_fpaths, aug_labels = [], []\n",
    "    classlist = os.listdir(aug_dir)\n",
    "    for target in classlist:\n",
    "        classpath = os.path.join(aug_dir, target)\n",
    "        flist = os.listdir(classpath)\n",
    "        for f in flist:\n",
    "            fpath = os.path.join(classpath, f)\n",
    "            aug_fpaths.append(fpath)\n",
    "            aug_labels.append(target)\n",
    "    Fseries = pd.Series(aug_fpaths, name='filepaths')\n",
    "    Lseries = pd.Series(aug_labels, name='labels')\n",
    "    aug_df = pd.concat([Fseries, Lseries], axis=1)\n",
    "    df = pd.concat([df, aug_df], axis=0).reset_index(drop=True)\n",
    "    print('Length of augmented dataframe is ', len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframes(sdir):\n",
    "    bad_images = []\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    classes = sorted(os.listdir(sdir))\n",
    "    \n",
    "    for klass in classes:\n",
    "        classpath = os.path.join(sdir, klass)\n",
    "        if not os.path.isdir(classpath):\n",
    "            continue\n",
    "        flist = sorted(os.listdir(classpath))\n",
    "        desc = f'{klass:23s}'\n",
    "        \n",
    "        for f in tqdm(flist, ncols=110, desc=desc, unit='file', colour='blue'):\n",
    "            fpath = os.path.join(classpath, f)\n",
    "            try:\n",
    "                img = cv2.imread(fpath)\n",
    "                shape = img.shape\n",
    "                filepaths.append(fpath)\n",
    "                labels.append(klass)\n",
    "            except Exception as e:\n",
    "                bad_images.append(fpath)\n",
    "                print(f'Defective image file: {fpath}, Error: {e}')\n",
    "    \n",
    "    Fseries = pd.Series(filepaths, name='filepaths')\n",
    "    Lseries = pd.Series(labels, name='labels')\n",
    "    df = pd.concat([Fseries, Lseries], axis=1)\n",
    "    \n",
    "    train_df, dummy_df = train_test_split(df, train_size=.8, shuffle=True, random_state=123, stratify=df['labels'])\n",
    "    valid_df, test_df = train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123, stratify=dummy_df['labels'])\n",
    "    \n",
    "    classes = sorted(train_df['labels'].unique())\n",
    "    class_count = len(classes)\n",
    "    sample_df = train_df.sample(n=50, replace=False)\n",
    "    \n",
    "    ht, wt, count = 0, 0, 0\n",
    "    for i in range(len(sample_df)):\n",
    "        fpath = sample_df['filepaths'].iloc[i]\n",
    "        try:\n",
    "            img = cv2.imread(fpath)\n",
    "            h, w = img.shape[:2]\n",
    "            ht += h\n",
    "            wt += w\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    if count > 0:\n",
    "        ave_height = ht // count\n",
    "        ave_width = wt // count\n",
    "        aspect_ratio = ave_height / ave_width\n",
    "    else:\n",
    "        ave_height, ave_width, aspect_ratio = 0, 0, 0\n",
    "    \n",
    "    print(f'Number of classes in processed dataset: {class_count}')\n",
    "    counts = list(train_df['labels'].value_counts())\n",
    "    print(f'Max files in any class in train_df: {max(counts)}, Min files in any class: {min(counts)}')\n",
    "    print(f'Train dataset length: {len(train_df)}, Test dataset length: {len(test_df)}, Validation dataset length: {len(valid_df)}')\n",
    "    print(f'Average image height: {ave_height}, Average image width: {ave_width}, Aspect ratio (height/width): {aspect_ratio}')\n",
    "    \n",
    "    return train_df, test_df, valid_df, classes, class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gens(batch_size, train_df, test_df, valid_df, img_size):\n",
    "    trgen = ImageDataGenerator(horizontal_flip=True)\n",
    "    t_and_v_gen = ImageDataGenerator()\n",
    "    \n",
    "    train_ds = trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels',\n",
    "                                       target_size=img_size, class_mode='categorical',\n",
    "                                       color_mode='rgb', batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    valid_ds = t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels',\n",
    "                                       target_size=img_size, class_mode='categorical',\n",
    "                                       color_mode='rgb', batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_len = len(test_df)\n",
    "    test_batch_size = sorted([int(test_len / n) for n in range(1, test_len + 1)\n",
    "                              if test_len % n == 0 and test_len / n<=80], reverse=True)[0]\n",
    "    test_steps = int(test_len / test_batch_size)\n",
    "    \n",
    "    test_ds = t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels',\n",
    "                                               target_size=img_size, class_mode='categorical',\n",
    "                                               color_mode='rgb', batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    classes = list(train_ds.class_indices.keys())\n",
    "    class_count = len(classes)\n",
    "    print('test batch size: ', test_batch_size, 'test steps: ', test_steps, 'number of classes : ', class_count)\n",
    "\n",
    "    return train_ds, test_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "sdir = 'D:/2011/folder1'\n",
    "train_df, test_df, valid_df, classes, class_count = make_dataframes(sdir)\n",
    "\n",
    "# Balance the training data\n",
    "n = 2500  # Số lượng mẫu mong muốn cho mỗi lớp\n",
    "working_dir = './'  # Thư mục làm việc\n",
    "train_df = balance(train_df, n, working_dir, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "# Create data generators\n",
    "train_ds, test_ds, valid_ds = make_gens(BATCH_SIZE, train_df, test_df, valid_df, (IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc_loss(history, epochs):\n",
    "    tloss = history.history['loss']\n",
    "    vloss = history.history['val_loss']\n",
    "\n",
    "    print(f\"Number of epochs: {epochs}\")\n",
    "    print(f\"Training loss data points: {len(tloss)}\")\n",
    "    print(f\"Validation loss data points: {len(vloss)}\")\n",
    "\n",
    "    if len(tloss) != epochs or len(vloss) != epochs:\n",
    "        print(\"Mismatch in number of epochs and data points. Adjusting to match.\")\n",
    "        epochs = min(len(tloss), len(vloss))\n",
    "\n",
    "    Epochs = range(1, epochs + 1)\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
    "\n",
    "    axes[0].plot(Epochs, tloss[:epochs], 'r', label='Training loss')\n",
    "    axes[0].plot(Epochs, vloss[:epochs], 'g', label='Validation loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "\n",
    "    if 'accuracy' in history.history:\n",
    "        tacc = history.history['accuracy']\n",
    "        vacc = history.history['val_accuracy']\n",
    "        axes[1].plot(Epochs, tacc[:epochs], 'r', label='Training accuracy')\n",
    "        axes[1].plot(Epochs, vacc[:epochs], 'g', label='Validation accuracy')\n",
    "        axes[1].set_title('Training and Validation accuracy')\n",
    "        axes[1].set_xlabel('Epochs')\n",
    "        axes[1].set_ylabel('accuracy')\n",
    "        axes[1].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(test_ds, model):\n",
    "    y_pred, error_list, error_pred_list = [], [], []\n",
    "    y_true = test_ds.labels\n",
    "    classes = list(test_ds.class_indices.keys())\n",
    "    class_count = len(classes)\n",
    "    errors = 0\n",
    "    preds = tf.argmax(model.predict(test_ds), axis=1)\n",
    "    tests = len(preds)\n",
    "    for i in range(tests):\n",
    "        pred_index = preds[i]\n",
    "        true_index = test_ds.labels[i]\n",
    "        if pred_index != true_index:\n",
    "            errors += 1\n",
    "            file = test_ds.filenames[i]\n",
    "            error_list.append(file)\n",
    "            error_classes = classes[pred_index]\n",
    "            error_pred_list.append(error_classes)\n",
    "        y_pred.append(pred_index)\n",
    "\n",
    "    acc = (1 - errors / tests) * 100\n",
    "    msg = f'there were {errors} errors in {tests} tests for an accuracy of {acc:6.2f}%'\n",
    "    print(msg)\n",
    "    ypred = np.array(y_pred)\n",
    "    ytrue = np.array(y_true)\n",
    "    f1score = f1_score(ytrue, ypred, average='weighted') * 100\n",
    "\n",
    "    if class_count <= 30:\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)\n",
    "        plt.xticks(np.arange(class_count) + .5, classes, rotation=90)\n",
    "        plt.yticks(np.arange(class_count) + .5, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    clr = classification_report(y_true, y_pred, target_names=classes, digits=4)\n",
    "    print(\"Classification Report:\\n----------------------\\n\", clr)\n",
    "\n",
    "    return errors, tests, error_list, error_pred_list, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.backend import clear_session\n",
    "# import gc\n",
    "# clear_session()\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile model\n",
    "base_model = EfficientNetB7(weights='imagenet',\n",
    "                           include_top=False,\n",
    "                           input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "x = tf.keras.layers.Flatten()(base_model.output)\n",
    "x = tf.keras.layers.Dense(512,activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(128,activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "prediction = tf.keras.layers.Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "efficient_net_model = Model(inputs=base_model.input, outputs=prediction)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='loss',\n",
    "                                          patience=2,\n",
    "                                          verbose=1,\n",
    "                                          factor=0.75,\n",
    "                                          min_lr=0.00001)\n",
    "\n",
    "efficient_net_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = efficient_net_model.fit(train_ds,\n",
    "                                steps_per_epoch=len(train_ds),\n",
    "                                validation_data=valid_ds,\n",
    "                                epochs=12,\n",
    "                                callbacks=[learning_rate_reduction],\n",
    "                                validation_steps=len(valid_ds),\n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_auc_loss(history, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "errors, tests, error_list, error_pred_list, f1score = predictor(test_ds, efficient_net_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "all_data = pd.concat([train_df, test_df, valid_df])\n",
    "class_counts_all = all_data['labels'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts_all.plot(kind='bar', color='skyblue')\n",
    "plt.title('Number of Samples per Class (All datasets)')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_net_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# saved_model_path = './model/efficientnet_b7'\n",
    "# efficient_net_model.save(saved_model_path, save_format='tf')\n",
    "# print(f\"Model saved as SavedModel at: {saved_model_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Chạy mô hình trên CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(efficient_net_model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    tflite_save_path = './model/efficientnet_b7.tflite'\n",
    "    with open(tflite_save_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Đường dẫn đến SavedModel đã lưu\n",
    "saved_model_path = './model/efficientnet_b7/'\n",
    "\n",
    "# Đường dẫn thư mục để lưu model TensorFlow.js\n",
    "tfjs_model_dir = './model/modeljs/B7'\n",
    "\n",
    "# Chuyển đổi model sang TensorFlow.js\n",
    "result = subprocess.run([\n",
    "    'tensorflowjs_converter',\n",
    "    '--input_format', 'tf_saved_model',\n",
    "    '--output_format', 'tfjs_graph_model',\n",
    "    '--saved_model_tags', 'serve',\n",
    "    saved_model_path,\n",
    "    tfjs_model_dir\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(f\"Lỗi trong quá trình chuyển đổi: {result.stderr}\")\n",
    "else:\n",
    "    print(f\"Model đã được chuyển đổi sang TensorFlow.js và lưu tại: {tfjs_model_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
